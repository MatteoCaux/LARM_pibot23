#!/usr/bin/env python3

import pyrealsense2 as rs
import signal, time, numpy as np
import sys, cv2, rclpy
from rclpy.node import Node
from cv_bridge import CvBridge
from sensor_msgs.msg import Image
from std_msgs.msg import String
from geometry_msgs.msg import Point32


# Realsense Node:
class Realsense(Node):
    def __init__(self, fps= 60):
        super().__init__('realsense')
        # Configure depth and color streams
        self.pipeline = rs.pipeline()
        config = rs.config()

        #compteur et flag pour fantome detecttion
        self.flag =0
        self.count = 0

        # Get device product line for setting a supporting resolution
        pipeline_wrapper = rs.pipeline_wrapper(self.pipeline)
        pipeline_profile = config.resolve(pipeline_wrapper)
        
        config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)
        config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)
        config.enable_stream(rs.stream.infrared, 1, 848, 480, rs.format.y8, 60)
        config.enable_stream(rs.stream.infrared, 2, 848, 480, rs.format.y8, 60)

        #create the publishers
        self.image_publisher = self.create_publisher(Image, 'sensor_msgs/cam_image',10)
        self.depth_publisher = self.create_publisher(Image, 'sensor_msgs/cam_depth',10)
        self.infra_publisher_1 = self.create_publisher(Image, 'sensor_msgs/infrared_1',10)
        self.infra_publisher_2 = self.create_publisher(Image, 'sensor_msgs/infrared_2',10)
        self.detection_vert= self.create_publisher(String, 'sensor_msgs/detection',10)
        self.coord = self.create_publisher(Point32, '/center',10)

        self.bridge=CvBridge()

        # Start streaming
        profile = self.pipeline.start(config)

        # get stream profile adn camera intrinsics
        color_profile = rs.video_stream_profile(profile.get_stream(rs.stream.color))
        self.color_intrinsics = color_profile.get_intrinsics()

        align_to = rs.stream.depth
        self.align = rs.align(align_to)

        self.crop=None
        self.color_info = (0,0,255)

        #def min et max pour le masque vert
        self.min_vert = np.array([50,100,50])
        self.max_vert = np.array([85,255,255])
        #min et max du noir
        self.min_noir = np.array([0,0,0])
        self.max_noir = np.array([255,255,30])
        #min et max du vert
        self.min_blanc = np.array([80,0,140])
        self.max_blanc = np.array([255,40,255])

    def read_imgs(self):
        # Wait for a coherent tuple of frames: depth, color and accel
        frames = self.pipeline.wait_for_frames()

        color_frame = frames.first(rs.stream.color)

        #creation de l'image aligne avec la depth
        aligned_frames =  self.align.process(frames)
        self.depth_frame = aligned_frames.get_depth_frame()
        aligned_color_frame = aligned_frames.get_color_frame()

        if not (self.depth_frame and color_frame):
            pass

        # Convert images to numpy arrays
        self.depth_image = np.asanyarray(self.depth_frame.get_data())
        self.color_image = np.asanyarray(color_frame.get_data())

        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)
        self.depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(self.depth_image, alpha=0.03), cv2.COLORMAP_JET)
    
    def read_infra(self):
        # Wait for a coherent tuple of frames: depth, color and accel
        frames = self.pipeline.wait_for_frames()

        infra_frame_1 = frames.get_infrared_frame(1)
        infra_frame_2 = frames.get_infrared_frame(2)

        infra_image_1 = np.asanyarray(infra_frame_1.get_data())
        infra_image_2 = np.asanyarray(infra_frame_2.get_data())

        # Utilisation de colormap sur l'image infrared de la Realsense (image convertie en 8-bit par pixel)
        self.infra_colormap_1 = cv2.applyColorMap(cv2.convertScaleAbs(infra_image_1, alpha=0.03), cv2.COLORMAP_JET)

        # Utilisation de colormap sur l'image infrared de la Realsense (image convertie en 8-bit par pixel)
        self.infra_colormap_2 = cv2.applyColorMap(cv2.convertScaleAbs(infra_image_2, alpha=0.03), cv2.COLORMAP_JET)
        
    def publish_imgs(self):
        msg_image = self.bridge.cv2_to_imgmsg(self.color_image,"bgr8")
        msg_image.header.stamp = self.get_clock().now().to_msg()
        msg_image.header.frame_id = "image"
        self.image_publisher.publish(msg_image)

        msg_depth = self.bridge.cv2_to_imgmsg(self.depth_colormap,"bgr8")
        msg_depth.header.stamp = msg_image.header.stamp
        msg_depth.header.frame_id = "depth"
        self.depth_publisher.publish(msg_depth)
    
    def publish_infra(self):
        msg_infra = self.bridge.cv2_to_imgmsg(self.infra_colormap_1,"bgr8")
        msg_infra.header.stamp = self.get_clock().now().to_msg()
        msg_infra.header.frame_id = "infrared_1"
        self.infra_publisher_1.publish(msg_infra)

        msg_infra = self.bridge.cv2_to_imgmsg(self.infra_colormap_2,"bgr8")
        msg_infra.header.stamp = msg_infra.header.stamp
        msg_infra.header.frame_id = "infrared_2"
        self.infra_publisher_2.publish(msg_infra)
        

    def filtre_couleur(self,image,mask_min,mask_max):
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        mask=cv2.inRange(hsv,mask_min,mask_max)
        # mask_vert = cv2.GaussianBlur(mask_vert,(11,11),0)

        kernel= np.ones((5,5),np.uint8)

        mask=cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernel)

        return mask

    def poseXYZ(self,pixel):
        if pixel is None : 
            return
        
        (px,py)=pixel

        depth = self.depth_frame.get_distance(px,py)

        point = rs.rs2_deproject_pixel_to_point(self.color_intrinsics,[px,py],depth)
        point= [point[0],point[1],point[2]]
        return point


    def fantome(self):
        #appel de la fonction filtre_couleur pour obtenir le masque vert
        self.mask_vert=self.filtre_couleur(self.color_image,self.min_vert,self.max_vert)

        #creation de la liste de contours 
        contours_vert=cv2.findContours(self.mask_vert, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]

        #compteur de contours
        nb_contours_vert = 0
        self.carre_vert = 0
        self.carre_noir=0
        self.oeil_blanc=0

        if len(contours_vert) > 0:
            for c in contours_vert :
                #recuperation du cercle et rectangle englobant
                ((self.x_vert, self.y_vert), self.rayon_vert)=cv2.minEnclosingCircle(c)
                rect=cv2.boundingRect(c)

                #variable du rectangle
                coin=rect[:2]
                largeur=rect[2]
                hauteur=rect[3]

                if self.rayon_vert>40:
                    nb_contours_vert += 1

                    #creation d'une image crop pour rechercher les yeux
                    x_max=coin[0]+largeur+10 if coin[0]+largeur+10 < self.color_image.shape[1] else coin[0]+largeur
                    y_max=coin[1]+hauteur + 10 if coin[1]+ + 10 < self.color_image.shape[0] else coin[1]+hauteur
                    y_min = coin[1] - 10 if coin[1] -10 > 0 else coin[1]
                    x_min = coin[0] - 10 if coin[0] -10 > 0 else coin[0]
                    self.crop = self.color_image[y_min:y_max,x_min:x_max]

                    if self.crop is not None : 
                        #appel de la fonction filtre_couleur pour obtenir les masques noir et blanc
                        mask_noir = self.filtre_couleur(self.crop,self.min_noir,self.max_noir)
                        mask_blanc = self.filtre_couleur(self.crop,self.min_blanc,self.max_blanc)
                        self.contours_interne(mask_noir,True)
                        self.contours_interne(mask_blanc,False)

                    self.carre_vert += 1

                    cv2.rectangle(self.color_image, coin, (coin[0]+largeur, coin[1]+hauteur),self.color_info, 2)
            if nb_contours_vert ==0 :
                self.carre_vert = 0

    def contours_interne(self, mask, noir):
        contours=cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
        if len(contours) > 0:
            for c in contours :
                ((x, y), rayon)=cv2.minEnclosingCircle(c)
                rect=cv2.boundingRect(c)

                largeur=rect[2]
                hauteur=rect[3]
                ratio = rayon/self.rayon_vert

                if noir :
                    carre = largeur/hauteur
                    iscarre = carre > 0.8 and carre < 1.2
                    isratio = ratio > 0.1 and ratio < 0.2
                else : 
                    iscarre = True
                    isratio = ratio < 0.35 and ratio > 0.25

                if isratio and iscarre  :
                    cv2.circle(self.crop, (int(x), int(y)), int(rayon), self.color_info, 2)
                    if noir : 
                        self.carre_noir+=1
                    else : 
                        self.oeil_blanc +=1

    def detection_fantome(self):
        if self.oeil_blanc >=1 and self.carre_noir >= 1 and self.carre_vert >=1 :
            self.count += 1
            msg = String()
            msg.data = "Un fantôme est détecté, c'est le numero " + str(self.count)
            self.detection_vert.publish(msg)
            coord = self.poseXYZ((int(self.x_vert),int(self.y_vert)))
            msg = Point32()
            msg.x = coord[0]
            msg.y = coord[1]
            msg.z = coord[2]
            self.coord.publish(msg)



    def show(self):
        # Show images
        #images = np.hstack((self.color_image, self.depth_colormap))#,self.infra_colormap_1,self.infra_colormap_2))
        #green = np.hstack((self.res2_vert,self.closing))

        # Show images
        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)
        cv2.imshow('RealSense', self.color_image)
        if self.crop is not None : 
            cv2.imshow('crop',self.crop)
        cv2.waitKey(1)


# Node processes:
def main(infra =False,show=False,args=None):
    rclpy.init(args=args)
    rsNode= Realsense()
    while isOk:
        rsNode.read_imgs()
        rsNode.publish_imgs()
        rsNode.fantome()
        # rsNode.voir_carre_noir()
        # rsNode.voir_yeux_blanc()

        rsNode.detection_fantome()
        if infra : 
            rsNode.read_infra()
            rsNode.publish_infra()
        if show : 
            rsNode.show()
        rclpy.spin_once(rsNode, timeout_sec=0.001)
    # Stop streaming
    print("Ending...")
    rsNode.pipeline.stop()
    # Clean end
    rsNode.destroy_node()
    rclpy.shutdown()

if __name__=="__main__":
    # Capture ctrl-c event
    isOk= True
    def signalInteruption(signum, frame):
        global isOk
        print( "\nCtrl-c pressed" )
        isOk= False

    signal.signal(signal.SIGINT, signalInteruption)

    main(False,True)