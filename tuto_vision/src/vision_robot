#!/usr/bin/env python3

import pyrealsense2 as rs
import signal, time, numpy as np
import sys, cv2, rclpy
from rclpy.node import Node
from cv_bridge import CvBridge
from sensor_msgs.msg import Image
from std_msgs.msg import String


# Realsense Node:
class Realsense(Node):
    def __init__(self, fps= 60):
        super().__init__('realsense')
        # Configure depth and color streams
        self.pipeline = rs.pipeline()
        config = rs.config()

        #counter et flag for fantome detecttion
        self.flag =0
        self.count = 0

        # Get device product line for setting a supporting resolution
        pipeline_wrapper = rs.pipeline_wrapper(self.pipeline)
        pipeline_profile = config.resolve(pipeline_wrapper)
        device = pipeline_profile.get_device()
        device_product_line = str(device.get_info(rs.camera_info.product_line))

        found_rgb = True
        for s in device.sensors:
            if s.get_info(rs.camera_info.name) == 'RGB Camera':
                found_rgb = True

        if not (found_rgb):
            print("Depth camera required !!!")
            exit(0)
        
        config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)
        config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)
        config.enable_stream(rs.stream.infrared, 1, 848, 480, rs.format.y8, 60)
        config.enable_stream(rs.stream.infrared, 2, 848, 480, rs.format.y8, 60)

        #create the publishers
        self.image_publisher = self.create_publisher(Image, 'sensor_msgs/cam_image',10)
        self.depth_publisher = self.create_publisher(Image, 'sensor_msgs/cam_depth',10)
        self.infra_publisher_1 = self.create_publisher(Image, 'sensor_msgs/infrared_1',10)
        self.infra_publisher_2 = self.create_publisher(Image, 'sensor_msgs/infrared_2',10)
        self.detection_vert= self.create_publisher(String, 'sensor_msgs/detection',10)

        self.bridge=CvBridge()

        # Start streaming
        self.pipeline.start(config)

    def read_imgs(self):
        # Wait for a coherent tuple of frames: depth, color and accel
        frames = self.pipeline.wait_for_frames()

        color_frame = frames.first(rs.stream.color)
        depth_frame = frames.first(rs.stream.depth)

        if not (depth_frame and color_frame):
            pass

        # Convert images to numpy arrays
        self.depth_image = np.asanyarray(depth_frame.get_data())
        self.color_image = np.asanyarray(color_frame.get_data())

        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)
        self.depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(self.depth_image, alpha=0.03), cv2.COLORMAP_JET)
    
    def read_infra(self):
        # Wait for a coherent tuple of frames: depth, color and accel
        frames = self.pipeline.wait_for_frames()

        infra_frame_1 = frames.get_infrared_frame(1)
        infra_frame_2 = frames.get_infrared_frame(2)

        infra_image_1 = np.asanyarray(infra_frame_1.get_data())
        infra_image_2 = np.asanyarray(infra_frame_2.get_data())

        # Utilisation de colormap sur l'image infrared de la Realsense (image convertie en 8-bit par pixel)
        self.infra_colormap_1 = cv2.applyColorMap(cv2.convertScaleAbs(infra_image_1, alpha=0.03), cv2.COLORMAP_JET)

        # Utilisation de colormap sur l'image infrared de la Realsense (image convertie en 8-bit par pixel)
        self.infra_colormap_2 = cv2.applyColorMap(cv2.convertScaleAbs(infra_image_2, alpha=0.03), cv2.COLORMAP_JET)
        


    def publish_imgs(self):
        msg_image = self.bridge.cv2_to_imgmsg(self.color_image,"bgr8")
        msg_image.header.stamp = self.get_clock().now().to_msg()
        msg_image.header.frame_id = "image"
        self.image_publisher.publish(msg_image)

        msg_depth = self.bridge.cv2_to_imgmsg(self.depth_colormap,"bgr8")
        msg_depth.header.stamp = msg_image.header.stamp
        msg_depth.header.frame_id = "depth"
        self.depth_publisher.publish(msg_depth)
    
    def publish_infra(self):
        msg_infra = self.bridge.cv2_to_imgmsg(self.infra_colormap_1,"bgr8")
        msg_infra.header.stamp = self.get_clock().now().to_msg()
        msg_infra.header.frame_id = "infrared_1"
        self.infra_publisher_1.publish(msg_infra)

        msg_infra = self.bridge.cv2_to_imgmsg(self.infra_colormap_2,"bgr8")
        msg_infra.header.stamp = msg_infra.header.stamp
        msg_infra.header.frame_id = "infrared_2"
        self.infra_publisher_2.publish(msg_infra)
        


    def filtre_vert(self):
        hsv = cv2.cvtColor(self.color_image, cv2.COLOR_BGR2HSV)
        
        #min et max du vert
        min_vert = np.array([50,80,80])
        max_vert = np.array([75,165,165])

        mask_vert=cv2.inRange(hsv,min_vert,max_vert)
        mask_vert = cv2.GaussianBlur(mask_vert,(11,11),0)

        kernel= np.ones((5,5),np.uint8)

        self.closing=cv2.morphologyEx(mask_vert,cv2.MORPH_OPEN,kernel)

        self.res2_vert = cv2.cvtColor(cv2.bitwise_and(self.color_image,self.color_image,mask=self.closing),cv2.COLOR_HSV2BGR)

    def contours(self):
        self.filtre_vert()
        contours=cv2.findContours(self.closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
        nb_contours = 0
        if len(contours) > 0:
            for c in contours :
                ((x, y), rayon)=cv2.minEnclosingCircle(c)
                rect=cv2.boundingRect(c)
                # print(rect)
                # print(rayon)
                coin=rect[:2]
                largeur=rect[2]
                hauteur=rect[3]
                if rayon>20:
                    nb_contours += 1
                    if self.flag == 0:
                        self.count += 1
                        msg = String()
                        msg.data = "Un fantôme est détecté, c'est le numéro: " + str(self.count)
                        self.detection_vert.publish(msg)
                        print(self.count)
                        print(nb_contours)
                    self.flag = 1
                    #cv2.circle(self.res2_vert, (int(x), int(y)), int(rayon), (0,0,255), 2)
                    cv2.rectangle(self.color_image, coin, (coin[0]+largeur, coin[1]+hauteur),(0,0,255), 2)
            if nb_contours ==0 :
                self.flag = 0
            

    def show(self):
        # Show images
        images = np.hstack((self.color_image, self.depth_colormap))#,self.infra_colormap_1,self.infra_colormap_2))
        #green = np.hstack((self.res2_vert,self.closing))

        # Show images
        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)
        cv2.imshow('RealSense', images)
        #cv2.imshow('vert',green)
        cv2.waitKey(1)


# Node processes:
def process_img(infra =False,show=False,args=None):
    rclpy.init(args=args)
    rsNode= Realsense()
    while isOk:
        rsNode.read_imgs()
        rsNode.publish_imgs()
        rsNode.contours()
        if infra : 
            rsNode.read_infra()
            rsNode.publish_infra()
        if show : 
            rsNode.show()
        rclpy.spin_once(rsNode, timeout_sec=0.001)
    # Stop streaming
    print("Ending...")
    rsNode.pipeline.stop()
    # Clean end
    rsNode.destroy_node()
    rclpy.shutdown()

if __name__=="__main__":
    # Capture ctrl-c event
    isOk= True
    def signalInteruption(signum, frame):
        global isOk
        print( "\nCtrl-c pressed" )
        isOk= False

    signal.signal(signal.SIGINT, signalInteruption)

    process_img(False,True)